{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89113f9-7253-444f-9ff9-1d85b6b1cae1",
   "metadata": {},
   "source": [
    "### Oben Özgür-150190719\n",
    "### Ömer Faruk Topal-150170029\n",
    "### Muzaffer Aydın-150170086\n",
    "### İhsan Mert Şahin-150170108\n",
    "### Hakan Toker-150170726"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "387731db-64bf-4316-b25f-fb105ea94535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----FOLD1-----\n",
      "1 outlier(s) detected and replaced by means of the set.\n",
      "MSE: 0.02321859403454745\n",
      "MAE: 0.12199322371207395\n",
      "Pearson: 0.7052614741226307\n",
      "\n",
      "-----FOLD2-----\n",
      "0 outlier(s) detected and replaced by means of the set.\n",
      "MSE: 0.025570723630232932\n",
      "MAE: 0.12721453342542471\n",
      "Pearson: 0.7294299483146065\n",
      "\n",
      "-----FOLD3-----\n",
      "1 outlier(s) detected and replaced by means of the set.\n",
      "MSE: 0.02272445560907092\n",
      "MAE: 0.12086838419625227\n",
      "Pearson: 0.7200137166487364\n",
      "\n",
      "-----FOLD4-----\n",
      "1 outlier(s) detected and replaced by means of the set.\n",
      "MSE: 0.023907339587979453\n",
      "MAE: 0.12391449318088549\n",
      "Pearson: 0.7360036734738696\n",
      "\n",
      "-----FOLD5-----\n",
      "1 outlier(s) detected and replaced by means of the set.\n",
      "MSE: 0.023822069230219917\n",
      "MAE: 0.12313871256646622\n",
      "Pearson: 0.7197635122879267\n",
      "\n",
      "Average MSE: 0.023848636418410136\n",
      "Average MAE: 0.12342586941622054\n",
      "Average Pearson: 0.722094464969554\n",
      "\n",
      "\n",
      "--------------------\n",
      "Making prediction...\n",
      "1 outlier(s) detected and replaced by means of the set.\n",
      "Learning procedure is done and written to 'output.csv' in melted form.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as r\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "r.seed(1)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    load_data function reads the low resolution and high resolution csv files for testing,\n",
    "    reads the low resolution csv file to predict and returns them 3 different numpy arrays.\n",
    "    As file names are predetermined, no input is needed.\n",
    "    \"\"\"\n",
    "    lr = pd.read_csv(\"train_LR.csv\")\n",
    "    hr = pd.read_csv(\"train_HR.csv\")\n",
    "    lr_test = pd.read_csv(\"test_LR.csv\")\n",
    "    lr_np = lr.values\n",
    "    hr_np = hr.values\n",
    "    lr_test_np = lr_test.values\n",
    "    return lr_np, hr_np, lr_test_np\n",
    "    \n",
    "    \n",
    "def write_output(predicted):\n",
    "    \"\"\"\n",
    "    write_output function takes the precicted array of nx3220020 and meltes it.\n",
    "    Upon melting the array, it is written the 'output.csv' file.\n",
    "    \"\"\"\n",
    "    melted = predicted.flatten()\n",
    "    DF = pd.DataFrame(melted)\n",
    "    DF.to_csv('output.csv', index=True)  \n",
    "    \n",
    "\n",
    "def preprocess(X,y,X_test,variance_threshold=0):\n",
    "    \"\"\"\n",
    "    preprocess function performs the preprocess operations in our pipeline to the given training set\n",
    "    Upon finishing the operations, it just returns the processed values.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Variance threshold check, if no variance -> drop the feature\n",
    "    var_threshold = VarianceThreshold(threshold=variance_threshold) #Get features that has some variance\n",
    "    var_threshold.fit(X) #Fit it\n",
    "    #Drop zero variance features, they are unlearnable\n",
    "    X = var_threshold.transform(X) \n",
    "    X_test = var_threshold.transform(X_test) \n",
    "    \n",
    "    \"\"\"\n",
    "    LocalOutlierFactor algorithm is used to detect outliers.\n",
    "    If an outlier is detected, it will be replaced by the mean of the set.\n",
    "    \"\"\"\n",
    "    clf = LocalOutlierFactor(n_neighbors = 2) #Get outlier classifier\n",
    "    clf.fit(X) #Fit to the set\n",
    "    y_pred_outliers = clf.fit_predict(X) #Predict outliers; 1 if not, -1 if putlier\n",
    "\n",
    "    num_of_outliers = 0\n",
    "    outliers = [] #outlier indexes\n",
    "\n",
    "    for i in range(y_pred_outliers.shape[0]):\n",
    "        if y_pred_outliers[i] == -1: \n",
    "            outliers.append(i) #get outliers indexes\n",
    "            num_of_outliers += 1 #count outliers\n",
    "    \n",
    "    #Replace the outlier with mean of the features for the training set\n",
    "    X[outliers] = X.mean(axis=0)\n",
    "    y[outliers] = y.mean(axis=0)\n",
    "    \n",
    "    print(str(num_of_outliers) + \" outlier(s) detected and replaced by means of the set.\") #prompt\n",
    "    \n",
    "    return X,y, X_test #Set processed data\n",
    "\n",
    "\n",
    "def train_model(X_train,y_train,X_test,lambda_term):\n",
    "    \"\"\"\n",
    "    In training, 'KernelRidge' regressor is used since it is a multioutput regressor by its nature\n",
    "    Only hyperparameter for the regressor is the alphda which defines the strength of regularization\n",
    "    \"\"\"\n",
    "    regressor = KernelRidge(alpha=lambda_term) #Get regressor\n",
    "    regressor.fit(X_train, y_train) #Fit the train data\n",
    "    y_pred = regressor.predict(X_test) #Predict test data\n",
    "    return y_pred #return predicted high resolution image\n",
    "\n",
    "\n",
    "def CV_5(X,y,lambda_term):\n",
    "    \"\"\"\n",
    "    Provides cross validation to check the required metrics with train data\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=5) #5 Folds\n",
    "    r.seed(1) #Set random seed\n",
    "    fold = 1 #fold counter\n",
    "    ms_errors = [] #MSE list\n",
    "    ma_erros = [] #MAE list\n",
    "    pearsons = [] #Pearson coefficient list\n",
    "    \n",
    "    for train, test in kf.split(X):\n",
    "        print(\"\\n-----FOLD\" + str(fold) + \"-----\")\n",
    "        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test] #Split data\n",
    "        \n",
    "        X_train, y_train, X_test = preprocess(X_train,y_train,X_test) #Preprocess train data\n",
    "        \n",
    "        y_pred = train_model(X_train,y_train,X_test,lambda_term) #Predict\n",
    "        \n",
    "        #Return metrics\n",
    "        ms_errors.append(mean_squared_error(y_pred, y_test))\n",
    "        ma_erros.append(mean_absolute_error(y_pred, y_test))\n",
    "        pearsons.append(pearsonr(y_pred.flatten(), y_test.flatten())[0])\n",
    "        print(\"MSE: \" + str(mean_squared_error(y_pred, y_test)))\n",
    "        print(\"MAE: \" + str(mean_absolute_error(y_pred, y_test)))\n",
    "        print(\"Pearson: \" + str(pearsonr(y_pred.flatten(), y_test.flatten())[0]))\n",
    "        fold += 1 #Iterate\n",
    "\n",
    "    #Average metrics across all folds\n",
    "    average_mse = sum(ms_errors)/len(ms_errors)\n",
    "    print(\"\\nAverage MSE: \"+str(average_mse))\n",
    "    \n",
    "    average_mae = sum(ma_erros)/len(ma_erros)\n",
    "    print(\"Average MAE: \"+str(average_mae))\n",
    "    \n",
    "    average_pearson = sum(pearsons)/len(pearsons)\n",
    "    print(\"Average Pearson: \"+str(average_pearson))\n",
    "\n",
    "    \n",
    "#----------MAIN PROGRAM----------#\n",
    "lr_train, hr_train, lr_test = load_data()\n",
    "\n",
    "CV_5(lr_train,hr_train,250) #Use 250 as regularization term\n",
    "\n",
    "#Training actual data\n",
    "print(\"\\n\\n--------------------\")\n",
    "print(\"Making prediction...\")\n",
    "\n",
    "lr_train, hr_train, lr_test = preprocess(lr_train, hr_train, lr_test) #Process whole training data\n",
    "predicted = train_model(lr_train ,hr_train, lr_test, 230) #Train with lamda=230 as regularization term\n",
    "write_output(predicted) #Write the predicted output\n",
    "\n",
    "print(\"Learning procedure is done and written to 'output.csv' in melted form.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca00b9-b97c-4965-894f-0790b3aedfe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
